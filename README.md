# ðŸ« COVID Ventilator Requirement Prediction (XGBoost)

Predicting whether a COVID-19 patient will require **invasive ventilation (intubation)** using structured clinical features (demographics + comorbidities + early clinical indicators).  
The objective is to support **triage-style risk stratification** under **class imbalance**.

> **Primary target:** `INTUBATED` (binary)

---

## ðŸ“Œ Project Overview

This repository implements a reproducible, research-style ML pipeline:

- **EDA â†’ feature engineering â†’ baseline â†’ Optuna tuning (CV + SMOTE) â†’ evaluation**
- Explicit handling of **class imbalance** (resampling + threshold tuning)
- Artefacts saved between stages (**figures + metrics tables + parameter summaries**) for transparent review

---

## ðŸ“Š Results (summary)

Final tuned XGBoost models achieved **moderate discrimination** and show the expected precisionâ€“recall trade-off under imbalance:

- **ROC-AUC:** ~0.67  
- **PR-AUC:** ~0.28 (above prevalence)  
- **F1:** ~0.36 (varies with threshold)  
- Threshold adjustment (e.g. **0.50 â†’ 0.45**) increases **recall** at the cost of **precision**

> Exact values depend on the chosen threshold and experimental configuration (SMOTE vs class-weight).

---

## ðŸ“‚ Repository Structure

```text
covid-ventilator-prediction-xgboost/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_baseline_model.ipynb
â”‚   â”œâ”€â”€ 03_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 04_smote_cv_optuna.ipynb
â”‚   â””â”€â”€ 05_evaluation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â”œâ”€â”€ optuna_utils.py
â”‚   â””â”€â”€ eval_utils.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                     # local only (download from Kaggle; not committed)
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                 # committed (PNG plots used in README / review)
â”‚   â”œâ”€â”€ *.csv                    # committed (metrics, thresholds, trials)
â”‚   â””â”€â”€ *.json                   # committed (params + summaries)
â”‚
â””â”€â”€ reports/                     # optional supporting PDFs (Stage 1/2)
    â”œâ”€â”€ OCMP5310_Stage1_Report.pdf
    â””â”€â”€ OCMP5310_Stage2_Report.pdf
```

---

## ðŸ—‚ï¸ About Results and Outputs

To keep the repo lightweight and easy to review:

âœ… **Committed to GitHub**
- `outputs/figures/*.png` (EDA + evaluation plots)
- `outputs/*.csv` (metrics tables, threshold sweep, Optuna trial summaries)
- `outputs/*.json` (best parameters, run summaries, feature dictionary)

âŒ **Not committed to GitHub**
- Raw dataset (`data/raw/`)
- Large intermediate datasets (e.g. `*.parquet`)
- Trained model binaries (e.g. `*.pkl`)

Everything excluded can be regenerated by running the notebooks in order.

---

## ðŸ“¥ Data source

Dataset: **COVID-19 Dataset (Mexico)** from Kaggle  
https://www.kaggle.com/datasets/meirnizri/covid19-dataset/data

**Raw data is intentionally not committed to GitHub.** Download the dataset and place it at:

```text
data/raw/Covid_Data.csv
```

---

## âš™ï¸ How to run

1) Create environment and install dependencies:
```bash
pip install -r requirements.txt
```

2) Run notebooks in order:
- `01_eda.ipynb` â†’ EDA + saved figures + summary artefacts in `/outputs`
- `02_baseline_model.ipynb` â†’ baseline modelling + baseline artefacts
- `03_feature_engineering.ipynb` â†’ feature variants / preprocessing artefacts
- `04_smote_cv_optuna.ipynb` â†’ Optuna hyperparameter optimisation with CV + SMOTE
- `05_evaluation.ipynb` â†’ final evaluation + threshold analysis

---

## ðŸ§ª Notes on modelling choices

- The modelling approach focuses on **XGBoost**, given its strong performance on structured/tabular clinical data and robustness under noisy, mixed-type features.
- Optimisation uses **Optuna** with cross-validation to reduce overfitting risk and improve generalisability.
- Metrics emphasise **recall, precision, F1, PR-AUC** due to the clinical cost of false negatives and class imbalance.
- Threshold selection is treated as a separate decision step (model outputs probabilities; deployment requires choosing a threshold aligned to risk tolerance).

---

## ðŸŽ“ Project provenance (academic context)

This repository is a **refactored and portfolio-ready version** of a University of Sydney postgraduate research assignment (OCMP5310) on predicting ventilator requirements for COVID-19 patients using a large coded clinical dataset.

- **Original submission:** compared **~5 model families** (breadth) across feature sets and imbalance strategies.
- **This refactor:** centres on **XGBoost** (depth) to demonstrate a clean end-to-end workflow with disciplined tuning (**Optuna + CV + SMOTE**) and threshold calibration, plus reproducible artefact generation.

> In short: the original assignment demonstrates *breadth* (multi-model comparison), while this repo demonstrates *depth* (one strong tabular model executed to a professional standard).

---

## ðŸ“˜ Reports (optional)

If you include the PDFs, they provide additional academic context (problem framing, methodology, discussion):

```text
reports/OCMP5310_Stage1_Report.pdf
reports/OCMP5310_Stage2_Report.pdf
```

---

## ðŸ§¾ References

- Chen, T. & Guestrin, C. (2016). *XGBoost: A Scalable Tree Boosting System.*
- Akiba, T. et al. (2019). *Optuna: A next-generation hyperparameter optimization framework.*
