# COVID Ventilator Requirement Prediction (XGBoost)

Predicting whether a COVID-19 patient will require invasive ventilation (intubation) using structured clinical features (demographics + comorbidities + early clinical indicators). The goal is to support triage-style risk stratification under class imbalance.

> **Primary target:** `INTUBATED` (binary)

---

## Highlights (what this project demonstrates)

- End-to-end ML workflow: **EDA → feature engineering → baseline → Optuna tuning (CV + SMOTE) → evaluation**
- Explicit handling of **class imbalance** (SMOTE and threshold tuning)
- Reproducible artefacts saved between stages (**figures + metrics tables + parameter summaries**)
- Practical evaluation using **ROC-AUC, PR-AUC, F1, precision, recall**
- Clear separation of **model selection**, **tuning**, and **threshold calibration** (research-style experimental discipline)

---

## Results (summary)

Final tuned XGBoost models achieved **moderate discrimination** and show the expected precision–recall trade-off under imbalance:

- **ROC-AUC:** ~0.67  
- **PR-AUC:** ~0.28 (above prevalence)
- **F1:** ~0.36 (varies with threshold)
- Threshold adjustment (e.g. 0.50 → 0.45) increases **recall** at the cost of **precision**

> Exact values depend on the chosen threshold and experimental configuration (SMOTE vs class-weight).

---

## Repository structure

```
covid-ventilator-prediction-xgboost/
├── notebooks/
│   ├── 01_eda.ipynb
│   ├── 02_baseline_model.ipynb
│   ├── 03_feature_engineering.ipynb
│   ├── 04_smote_cv_optuna.ipynb
│   └── 05_evaluation.ipynb
├── src/
│   ├── data_utils.py
│   ├── model_utils.py
│   ├── optuna_utils.py
│   └── eval_utils.py
├── data/
│   └── raw/                    # local only (download from Kaggle; not committed)
├── outputs/
│   ├── figures/                # committed (PNG figures used in README / review)
│   ├── *.csv                    # committed (tables: metrics, thresholds, trials)
│   └── *.json                   # committed (params + summaries)
├── reports/                     # optional supporting PDFs (Stage 1/2)
│   ├── OCMP5310_Stage1_Report.pdf
│   └── OCMP5310_Stage2_Report.pdf
├── requirements.txt
└── .gitignore
```

---

## Data source

Dataset: **COVID-19 Dataset (Mexico)** from Kaggle  
https://www.kaggle.com/datasets/meirnizri/covid19-dataset/data

**Raw data is intentionally not committed to GitHub.** Download the dataset from Kaggle and place it at:

`data/raw/Covid_Data.csv`

---

## Outputs & reproducibility policy

To keep the repository lightweight and easy to review:

✅ **Committed to GitHub**
- `outputs/figures/*.png` (EDA + evaluation plots)
- `outputs/*.csv` (metrics tables, threshold sweep, Optuna trial summaries)
- `outputs/*.json` (best parameters, run summaries, feature dictionary)

❌ **Not committed to GitHub**
- Raw dataset (`data/raw/`)
- Large intermediate datasets (e.g. `*.parquet`)
- Trained model binaries (e.g. `*.pkl`)

Everything excluded can be regenerated by running the notebooks in order.

---

## How to run

1. Create environment and install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

2. Run notebooks in order:
   - `01_eda.ipynb` → EDA + saved figures + summary artefacts in `/outputs`
   - `02_baseline_model.ipynb` → baseline modelling + baseline artefacts
   - `03_feature_engineering.ipynb` → feature variants / preprocessing artefacts
   - `04_smote_cv_optuna.ipynb` → Optuna hyperparameter optimisation with CV + SMOTE
   - `05_evaluation.ipynb` → final evaluation + threshold analysis

---

## Notes on modelling choices

- The modelling approach focuses on **XGBoost**, given its strong performance on structured/tabular clinical data and robustness under noisy, mixed-type features.
- Optimisation uses **Optuna** with cross-validation to reduce overfitting risk and improve generalisability.
- Metrics emphasise **recall, precision, F1, PR-AUC** due to the clinical cost of false negatives and class imbalance.
- Threshold selection is treated as a separate decision step (model outputs probabilities; deployment requires choosing a threshold aligned to risk tolerance).

---

## Project provenance (academic context)

This repository is based on a **University of Sydney postgraduate Data Science research assignment** focused on predicting ventilation requirements for COVID-19 patients using a large, coded clinical dataset.

### What the original assignment did
The original submission explored a **multi-model experimental setup**, comparing several model families (e.g., linear/logistic baselines and tree-based ensemble methods) under different feature sets and imbalance strategies. The aim was to understand:
- how modelling assumptions affect performance under class imbalance,
- which features contribute most to predictive signal,
- and how model selection changes when prioritising sensitivity vs precision.

### What this refactored repository changes (and why)
For portfolio and reproducibility purposes, this repository **refactors the workflow into a clean, notebook-driven pipeline** and **centres the final modelling effort around XGBoost**.

XGBoost was selected as the “flagship” model in this refactor because it:
- is a strong, widely-used baseline for **tabular clinical risk modelling**,
- handles non-linear interactions and sparse/encoded clinical features effectively,
- provides a clear path to disciplined optimisation (CV + Optuna) and threshold calibration,
- and offers a good balance of performance and interpretability (via feature importance / SHAP-style extensions).

Rather than presenting many partially tuned models, the refactor prioritises **depth and methodological correctness**:
- explicit leakage controls,
- resampling inside cross-validation (SMOTE-in-CV),
- consistent artefact saving between stages,
- and evaluation that reflects real-world decision trade-offs (threshold sensitivity).

> In short: the original assignment demonstrates breadth (multiple models) while the refactored repo demonstrates depth (one model executed to a professional and reproducible standard).

---

## References

- Chen, T. & Guestrin, C. (2016). *XGBoost: A Scalable Tree Boosting System.*
- Akiba, T. et al. (2019). *Optuna: A next-generation hyperparameter optimization framework.*
